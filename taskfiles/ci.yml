version: '3'

tasks:

  configure:
    desc: "Configure a CI agent"
    cmds:
    # operator go test is using at least 2 k3d clusters which might exhaust limits of opened files
    - task: set-aio-max
    - task: set-inotify-watches
    - task: set-inotify-instances
    - task: configure-git-private-repo

  lint:
    cmds:
      - task: :generate
      - task: :lint
      # Fail on any generated diffs.
      - git diff --exit-code

  test:unit:
    cmds:
      - defer: 'buildkite-agent artifact upload "{{.SRC_DIR}}/unit-tests-*.xml"'
      - task: :test:unit
        vars:
          GO_TEST_RUNNER: gotestsum --raw-command --junitfile=unit-tests-%.xml -- go test
          CLI_ARGS: '-json {{.CLI_ARGS}}'

  test:integration:
    cmds:
      - defer: 'kind delete clusters --all'
      - task: :charts:kind-cluster
      - defer: 'buildkite-agent artifact upload "{{.SRC_DIR}}/integration-tests-*.xml"'
      - task: :test:integration
        vars:
          GO_TEST_RUNNER: gotestsum --raw-command --junitfile=integration-tests-%.xml -- go test
          CLI_ARGS: '-json {{.CLI_ARGS}}'

  test:acceptance:
    cmds:
      - defer: 'kind delete clusters --all'
      - task: :charts:kind-cluster
      - defer: 'buildkite-agent artifact upload "{{.SRC_DIR}}/acceptance-tests-*.xml"'
      - task: :test:acceptance
        vars:
          GO_TEST_RUNNER: gotestsum --raw-command --junitfile=acceptance-tests-%.xml -- go test
          CLI_ARGS: '-json {{.CLI_ARGS}}'

  test:kuttl-v1:
    cmds:
      - 'echo "~~~ Running kuttl V1 tests :k8s:"'
      - task: run-kuttl-tests

  test:kuttl-v1-nodepools:
    cmds:
      - 'echo "~~~ Running kuttl V1 Nodepools tests :k8s:"'
      - task: run-kuttl-tests
        vars:
          KUTTL_CONFIG_FILE: kuttl-test-with-flags.yaml

  test:kuttl-v2:
    cmds:
      - 'echo "~~~ Running kuttl V2 tests :k8s:"'
      - task: run-kuttl-tests
        vars:
          KUTTL_CONFIG_FILE: kuttl-v2-test.yaml

  configure-git-private-repo:
    internal: true
    env:
      GITHUB_TOKEN:
        sh: echo "${GITHUB_TOKEN:-$GITHUB_API_TOKEN}"
    cmds:
      - git config --global url."https://$GITHUB_TOKEN@github.com/".insteadOf "https://github.com/"
    preconditions:
      - test -n "$GITHUB_API_TOKEN" || test -n "$GITHUB_TOKEN"

  run-kuttl-tests:
    cmds:
      - defer:
          task: ci:kuttl-artifact-upload
          vars:
            KUTTL_CONFIG_FILE: '{{.KUTTL_CONFIG_FILE}}'
      - task: :k8s:run-kuttl-tests
        vars:
          KUTTL_CONFIG_FILE: '{{.KUTTL_CONFIG_FILE}}'

  kuttl-artifact-upload:
    internal: true
    desc: uploads artifact when kuttl fails
    dir: operator
    summary: |
      kuttl-artifact-upload should be called in `defer`.
      https://taskfile.dev/usage/#doing-task-cleanup-with-defer

      As buildkite pipeline step are wrapped with shell script, that executes
      docker run of a NIX container, where the permission are set to user of
      ID 0 (root). The buildkite agent executor can not resolve glob due to
      not sufficient permission. All invocation, within taskfile, of
      `buildkite-agent artifact upload` will have sufficient permission.
    vars:
      KUTTL_CONFIG_FILE: '{{default "kuttl-test.yaml" .KUTTL_CONFIG_FILE}}'
      KUTTL_ARTIFACTS_DIR:
        sh: |
          cat {{.KUTTL_CONFIG_FILE}} | grep artifactsDir | awk '{print $2}'
    cmds:
      - tar -czf {{.KUTTL_ARTIFACTS_DIR | base}}.tar.gz {{.KUTTL_ARTIFACTS_DIR}}
      - buildkite-agent artifact upload "{{.SRC_DIR}}/operator/{{.KUTTL_ARTIFACTS_DIR | base}}.tar.gz"
      - buildkite-agent artifact upload "{{.SRC_DIR}}/operator/{{.KUTTL_ARTIFACTS_DIR}}/kuttl-report.xml"

  publish-operator-image:
    deps:
      - :dev:create-buildx-builder
    cmds:
      - 'echo "~~~ Logging into Dockerhub :docker:"'
      - cmd: docker login --username {{.DOCKERHUB_USER}} --password {{.DOCKERHUB_TOKEN}}
        silent: true
      - defer: docker logout
      - 'echo "~~~ Tagging and uploading images to Dockerhub :docker:"'
      - task: :build:operator-image
        vars:
          TAGS:
          - docker.io/vectorized/redpanda-operator:{{.OPERATOR_VERSION}}
          - docker.io/redpandadata/redpanda-operator:{{.OPERATOR_VERSION}}
          PLATFORMS:
          - linux/amd64
          - linux/arm64
          CLI_ARGS: "--push"

  publish-nightly-artifacts:
    deps:
      - :dev:create-buildx-builder
    cmds:
      - 'echo "~~~ Logging into Dockerhub :docker:"'
      - cmd: docker login --username {{.DOCKERHUB_USER}} --password {{.DOCKERHUB_TOKEN}}
        silent: true
      - defer: docker logout
      - cmd: aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/l9j0i2e0
        silent: true
      - defer: docker logout public.ecr.aws
      - 'echo "~~~ Tagging and uploading images to nightly Dockerhub :docker:"'
      - task: :build:operator-image
        vars:
          TAGS:
          - docker.io/redpandadata/redpanda-operator-nightly:{{.OPERATOR_VERSION}}
          - public.ecr.aws/l9j0i2e0/redpanda-operator-nightly:{{.OPERATOR_VERSION}}
          PLATFORMS:
          - linux/amd64
          - linux/arm64
          CLI_ARGS: "--push"
      # Package and push Operator helm chart to Dockerhub
      - task: :k8s:package-and-publish-operator-chart

  set-aio-max:
    internal: true
    desc: set minimum required value for fs.aio-max-nr sysctl option
    vars:
      MIN_REQUIRED_AIO_MAX: 20971520
      USE_SUDO: '{{default "false" .USE_SUDO}}'
    cmds:
      - 'echo "Setting fs.aio-max-nr sysctl option to {{.MIN_REQUIRED_AIO_MAX}}"'
      - '{{if eq .USE_SUDO "true"}}echo "Please enter your sudo password: "{{end}}'
      - '{{if eq .USE_SUDO "true"}}sudo {{end}}sysctl -w fs.aio-max-nr={{.MIN_REQUIRED_AIO_MAX}}'
    status:
      - test {{.MIN_REQUIRED_AIO_MAX}} -le $(sysctl -nb fs.aio-max-nr)
    platforms:
      - linux

  set-inotify-watches:
    internal: true
    desc: |
      set minimum required value for fs.inotify.max_user_watches sysctl option
      REF: https://kind.sigs.k8s.io/docs/user/known-issues/#pod-errors-due-to-too-many-open-files
    vars:
      MIN_REQUIRED_USER_WATCHES: 1310720
      USE_SUDO: '{{default "false" .USE_SUDO}}'
    cmds:
      - '{{if eq .USE_SUDO "true"}}sudo {{end}}sysctl -w fs.inotify.max_user_watches={{.MIN_REQUIRED_USER_WATCHES}}'
    status:
      - test {{.MIN_REQUIRED_USER_WATCHES}} -le $(sysctl -nb fs.inotify.max_user_watches)
    platforms:
      - linux

  set-inotify-instances:
    internal: true
    desc: |
      set minimum required value for fs.inotify.max_user_instances sysctl option
      REF: https://kind.sigs.k8s.io/docs/user/known-issues/#pod-errors-due-to-too-many-open-files
    vars:
      MIN_REQUIRED_USER_INSTANCES: 2560
      USE_SUDO: '{{default "false" .USE_SUDO}}'
    cmds:
      - '{{if eq .USE_SUDO "true"}}sudo {{end}}sysctl -w fs.inotify.max_user_instances={{.MIN_REQUIRED_USER_INSTANCES}}'
    status:
      - test {{.MIN_REQUIRED_USER_INSTANCES}} -le $(sysctl -nb fs.inotify.max_user_instances)
    platforms:
      - linux
